{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "funny-penalty",
   "metadata": {},
   "source": [
    "# Transcribe and Dataframe Creation\n",
    "This file was used for transcribing MP3 files and creating the initial dataframe\n",
    "\n",
    "## Set Up\n",
    "In this file, we uploaded all of the files from our S3 bucket titled \"napoli-bucket\" to the Github repo \"Napoli-Polly\".\n",
    "\n",
    "The first step was to determine whether all of our MP3 files were in the S3 bucket. We did this by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "connected-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 ls napoli-project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-worse",
   "metadata": {},
   "source": [
    "Once we saw that 11 MP3 files for each of the 4 languages were in the bucket, we pushed them to our SageMaker folder (which was also our Github repo). \n",
    "\n",
    "Next, we got started creating a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "durable-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 cp s3://napoli-project/ ../Napoli-Polly/MP3\\ files --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-rolling",
   "metadata": {},
   "source": [
    "We need to import the following 4 packages so that the code can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "processed-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-dialogue",
   "metadata": {},
   "source": [
    "The following are the resources that we utilized in this project:\n",
    "1. s3_resource : The S3 bucket\n",
    "\n",
    "2. polly : The client that created the MP3 files\n",
    "\n",
    "3. transcribe : The client that transcribes MP3 files\n",
    "\n",
    "4. napoli_bucket : The bucket where our files were all stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "medium-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource('s3') \n",
    "\n",
    "polly = boto3.client('polly') \n",
    "transcribe = boto3.client('transcribe')\n",
    "\n",
    "napoli_bucket = s3_resource.Bucket('napoli-project')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-central",
   "metadata": {},
   "source": [
    "Create a variable that holds all of the objects in our S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gorgeous-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = napoli_bucket.objects.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-skirt",
   "metadata": {},
   "source": [
    "## Dataframe Creation\n",
    "Creating a new dataframe and adding the names of each file to the dataframe. This dataframe is the basis that we will be working with throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-watts",
   "metadata": {},
   "source": [
    "Extracting the names from each MP3 file in the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interior-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_names = [mp3.key for mp3 in summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Names'] = mp3_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-sapphire",
   "metadata": {},
   "source": [
    "## Function 1: \n",
    "\n",
    "In this function, we take the name of each MP3 file and output its transcription using AWS Transcribe. When executing this code, it is critical that all job names are unique, as once they are run, you cannot rerun them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "electoral-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe each file\n",
    "def transcribe_job(file_name):\n",
    "    \n",
    "    # Define path to the file\n",
    "    job_uri = \"s3://napoli-project/\"+file_name\n",
    "    # Define unique job name\n",
    "    job_name = file_name + \"df1\"\n",
    "    \n",
    "    # Transcription settings\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='mp3',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "    # Extracting the transcription from the json\n",
    "    if result['TranscriptionJob']['TranscriptionJobStatus'] == \"COMPLETED\":\n",
    "        data = pd.read_json(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    # Diving deeper into the json to extract the transcript\n",
    "    return data['results'][1][0]['transcript']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-observer",
   "metadata": {},
   "source": [
    "## Function 2:\n",
    "\n",
    "This function gives us the average confidence level that AWS Transcribe measures for each sentence.\n",
    "AWS Transcribe outputs a confience score for each word that it transcribes. In the function, we focus our output to be the mean confidence of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "suitable-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_confidence(file_name):\n",
    "    # Define path to the file\n",
    "    job_uri = 's3://napoli-project/'+file_name\n",
    "    # Define unique job name\n",
    "    job_name = file_name + 'df2'\n",
    "\n",
    "    # Transcription settings\n",
    "    transcribe.start_transcription_job(\n",
    "        TranscriptionJobName=job_name,\n",
    "        Media={'MediaFileUri': job_uri},\n",
    "        MediaFormat='mp3',\n",
    "        LanguageCode='en-US'\n",
    "    )\n",
    "    while True:\n",
    "        result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "        if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "    if result['TranscriptionJob']['TranscriptionJobStatus'] == \"COMPLETED\":\n",
    "        data = pd.read_json(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
    "    \n",
    "    # Computing the mean of confidence for each sentence\n",
    "    sum_conf = 0\n",
    "    for i in range(len(data['results'][0])):\n",
    "        try:\n",
    "            # Diving deeper into the json to extract the confidence\n",
    "            sum_conf = sum_conf + float(data['results'][0][i][\"alternatives\"][0][\"confidence\"])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Define mean\n",
    "    mean = sum_conf / len(data['results'][0])\n",
    "  \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-communist",
   "metadata": {},
   "source": [
    "### Background on levels\n",
    "\n",
    "**Levels for transcript**\n",
    "\n",
    "A common theme in these functions was the use of brackets `[]` to extract information. The output from a Transription job includes multiple levels. To get to the confidence, we can filter our result all the way down using the following:\n",
    "\n",
    "`data['results'][1][0]['transcript']`\n",
    "\n",
    "First, we take the data and select the `[results]`. This can be further broken down by extracting the second value \"transcripts\". In our case, Python is 0 indexed, so the correct element in results is [1]:\n",
    "\n",
    "`data['results'][1]`\n",
    "\n",
    "The next layer is the transcript, but this is embedded in a folder `[0]`. All that is left, now, is to select the full transcript. This leads us back up to the following:\n",
    "\n",
    "`data['results'][1][0]['transcript']`\n",
    "\n",
    "**Levels for confidence**\n",
    "\n",
    "To extract the confidence level of each word, we can do the same. We first select data['results'], but now since we want confidence, which is in the 1st folder, we choose the 1st element.\n",
    "\n",
    "`data['results'][0]`\n",
    "\n",
    "Then, since we are iterating through each word in the sentence, we take the i'th word, and filter further to the \"alternatives\" folder.\n",
    "`data['results'][0][i][\"alternatives\"]`\n",
    "\n",
    "Next, we select the first folder again, which holds the confidence level of the word.\n",
    "`data['results'][0][i][\"alternatives\"][0]`\n",
    "\n",
    "Lastly, select the \"confidence\" element. These are values between 0 and 1 that tell us how confident Transcribe is in its ability to discern the MP3 files.\n",
    "`data['results'][0][i][\"alternatives\"][0][\"confidence\"]`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-sword",
   "metadata": {},
   "source": [
    "## Dataframe Creation (Continued)\n",
    "Now that the functions are created, let's apply them to each file. We have 44 mp3 files.\n",
    "\n",
    "Using the `.apply()` function, we can easily create a new column in our dataframe that holds the transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "incident-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Transcript'] = data['Names'].apply(transcribe_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-collar",
   "metadata": {},
   "source": [
    "Before moving on, we saved our progress. You can convert a dataframe to a .csv file using the `.to_csv()`, and uploaded the file to our new bucket called \"napoli-project-analysis\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "absent-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp Data.csv s3://napoli-project-analysis/Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-reception",
   "metadata": {},
   "source": [
    "Once the Transcriptions were added to the dataframe, we added the confidence scores for each file. We did this similarly, by applying the `transcribe_confidence` function to each MP3 file. The new column is called \"Confidence\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "demanding-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Confidence'] = data['Names'].apply(transcribe_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "upset-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "pressed-tragedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./Data.csv to s3://napoli-project-analysis/Data.csv    \n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp Data.csv s3://napoli-project-analysis/Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-concert",
   "metadata": {},
   "source": [
    "**Let's take a look at our dataframe!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eleven-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english-batter-barter.mp3</td>\n",
       "      <td>The batter is ready to swing on the next pitch...</td>\n",
       "      <td>0.906591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>english-beat-bit.mp3</td>\n",
       "      <td>The beat is a bit off, but I'm sure with enoug...</td>\n",
       "      <td>0.892737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>english-crazy-glue-sticky.mp3</td>\n",
       "      <td>The crazy glue is extremely sticky.</td>\n",
       "      <td>0.765429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english-croissant.mp3</td>\n",
       "      <td>Alexa Where did I leave my Khorasan?</td>\n",
       "      <td>0.767625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>english-look-luke.mp3</td>\n",
       "      <td>Look at the clouds luke.</td>\n",
       "      <td>0.799667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Names  \\\n",
       "0      english-batter-barter.mp3   \n",
       "1           english-beat-bit.mp3   \n",
       "2  english-crazy-glue-sticky.mp3   \n",
       "3          english-croissant.mp3   \n",
       "4          english-look-luke.mp3   \n",
       "\n",
       "                                          Transcript  Confidence  \n",
       "0  The batter is ready to swing on the next pitch...    0.906591  \n",
       "1  The beat is a bit off, but I'm sure with enoug...    0.892737  \n",
       "2                The crazy glue is extremely sticky.    0.765429  \n",
       "3               Alexa Where did I leave my Khorasan?    0.767625  \n",
       "4                           Look at the clouds luke.    0.799667  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-sleeve",
   "metadata": {},
   "source": [
    "To view the dataframe in your browser, click the following link:\n",
    "[Data.csv](https://napoli-project-analysis.s3.amazonaws.com/Data.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-retail",
   "metadata": {},
   "source": [
    "# Alternative way to extract jsons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-welding",
   "metadata": {},
   "source": [
    "### Breaking down Transcribe\n",
    "\n",
    "Say you have the following MP3 file:\n",
    "* english-batter-barter.mp3 \n",
    "\n",
    "To create new jobs, we have to define the path to the files, as well as create a job name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 ls napoli-project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_uri = \"s3://napoli-project/english-batter-barter.mp3\"\n",
    "job_name= \"english-batter-barter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-warehouse",
   "metadata": {},
   "source": [
    "In order to run our Transcribe call, you need to import `time`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "painted-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appropriate-retention",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TranscriptionJob': {'TranscriptionJobName': 'english-batter-barter', 'TranscriptionJobStatus': 'COMPLETED', 'LanguageCode': 'en-US', 'MediaSampleRateHertz': 22050, 'MediaFormat': 'mp3', 'Media': {'MediaFileUri': 's3://napoli-project/english-batter-barter.mp3'}, 'Transcript': {'TranscriptFileUri': 'https://s3.us-east-1.amazonaws.com/aws-transcribe-us-east-1-prod/795731225536/english-batter-barter/3ba46f68-6d2d-412f-9432-92edf7f71c4a/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFUaCXVzLWVhc3QtMSJIMEYCIQDjoAI8IhweBZ6pOPmxCNXq%2B5DiWlhFe3rye8gjcDqFWwIhAKohFtJE93EYkZPmcK1LLz5Whq4lSNbWpOEi10iD30Z6Kr0DCL7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQAhoMMjc2NjU2NDMzMTUzIgxo5H67S%2BZb5dhRnG4qkQOsBzWHpOi%2FpGAtu9mTP7bCJU%2F5thvKme6Y5ns5FJx6bXh7CC2QX7I0EERKrMgzOw1MSRo3GO%2F9n1Nrc3QS%2FlCL1oVQUzLm0VDFe41akIScWn%2F6Eb1SLKTSv0RV1I%2B1l%2FqmKhirKVLV3kDGKFP5kgIjkIK0bZfmvTqCctmYdnsm3Js08TqA0fNB0HyH6L2SR%2BOApknTLdi5GM%2BAZCuZALQMEiv3rfTyM%2BGTXkMO00HEQ55NMWo2rRK%2FUERmJ1eIc2qHVMC6hyjkqqO%2FxYnLlfVLi9gf3tLE2ntv0BJ0%2B%2Bjaib1gfo6hD1uxcPzwOLWDq827MlWQFzqs4YMF5D9Agw49kCHmygtMdqhWDdZ79am4EOq7xIjto0lPXmeNheglZY6%2BxGMh2G16kG4pZK01bY%2BEuj15Nv1m8yav3rhKXzzBMlVFDMeLISnfgTo5wjPql9QHJ1Y9t29RU5QyjdvVMVzl%2F3ivbQsTjmdMkcNF9GyV3Vb4n%2Bkfx%2BRk2Y%2BtimnhLY48lKi30sx6XUQx7yzlMBH0RTCz2oWEBjrqAQ8WfMLIDSSXcjJns5KbSEp2amefEPKtO86P%2BQXt4em85BtrY4RdV0WGX4CpIPi9nHEDEgA342r5E2pz3lZ6nqA%2BCN3RV6AsiVnFnls7GRfiLN9KV1hiP4dneSavEzGCa%2Ft93rd7yFuqXr%2FBdoEegvrRw9bbIhe%2FzwmUPZ%2FSWCK5KUTRi3m5gabfoXh%2F%2BVtng5Q5U9fRqPcSisa9xhjyixyaLCFOXnphHWo8qX4%2FfjUJ6m7h8htHyiaZrkaFNKQhzUBqF6VRlulI%2BIyKAy2ouBSBDh8y2PtWcpSKUYOFMtlopIoHZFeulu7Epw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210422T141433Z&X-Amz-SignedHeaders=host&X-Amz-Expires=899&X-Amz-Credential=ASIAUA2QCFAA4LL33BMZ%2F20210422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=e5b986b515372d4f12c1a1a79fe6201b1ab1dfccc28632845807d0849ff9363f'}, 'StartTime': datetime.datetime(2021, 4, 22, 14, 13, 25, 490000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2021, 4, 22, 14, 13, 25, 458000, tzinfo=tzlocal()), 'CompletionTime': datetime.datetime(2021, 4, 22, 14, 13, 46, 326000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}}, 'ResponseMetadata': {'RequestId': '04fcd8de-123b-4a55-b6e2-6e741710c1bd', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Thu, 22 Apr 2021 14:14:33 GMT', 'x-amzn-requestid': '04fcd8de-123b-4a55-b6e2-6e741710c1bd', 'content-length': '2034', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# This code transcribes our .mp3 files \n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name + \"0\",\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='mp3',\n",
    "    LanguageCode='en-US'\n",
    ")\n",
    "# This tells Python to tell us that it is transcribing\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "# This prints the TranscriptionJob\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-comparative",
   "metadata": {},
   "source": [
    "Now that the transcriptoin has been created, we can call the transcription and save it as a new variable. Use `.get_transcription_job` to select the job that was just created.\n",
    "\n",
    "After that, you can access the Uri path by using brackets (similar to what was done above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "every-enhancement",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.us-east-1.amazonaws.com/aws-transcribe-us-east-1-prod/795731225536/english-batter-barter/3ba46f68-6d2d-412f-9432-92edf7f71c4a/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFUaCXVzLWVhc3QtMSJGMEQCH0NcVrSHmc0hBvF1HoUpgo%2FJw5%2B7SOnizUSXXIoHemoCIQC9wr9SyUWq7%2FVQE3kviBlf4xexU8qONzyPwPTXtsoeZSq9Awi%2B%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAIaDDI3NjY1NjQzMzE1MyIM42SgSWP4DYU7KQ7CKpEDAIIT5WYrAJBHZgTXapiAM3r8ZtYDIw3fHf9LA%2Fp53F6RWXhDfAN1XzaXUIFMsshhox9G%2F%2B0Rj2C%2BotbvRcD2vAHVkkcxWZJ%2Bc61M2qQm4YzYRvWIWE4LaTgpcxA%2B2gsILh19LhWDHBl1ZYHBuh0yz8mdEM1p6nxgwcQpA9iokIB%2B2PWzDtS102nOFI1YnhQ%2BvYmKVs1jlF%2Bj%2B3iCY0Q3sihIkakj7oF%2FzU%2FJ9srxzNNxnlZgwUjfjlX5E4OBkZjmtW%2F3fT92iOJaMrvfPbXwBSat44VS4AkdLtBaBVJleUJMg3lVrKb98zrZzvQF8vVs5PwMy9SuJ5F99j2uMG6n%2BzcLx0MuXduYtGZaYnA2v1kRx63A1qV%2F2m%2FIRZnwqK6p%2FBYigrxr9ZlPsSawmC0Tq%2BbZ5JCITcdtloKcNTuHmnwWEGJLv%2FhLrdoQgvZ8FJEs3fiaW9umVZf2ZZ9WccKr9PwunYMLtXn7WeX64ov4Sfwycymtn3mfjcoMezcaw4dvi%2BJmjlRCvh9UK0YI1o%2FiFJIwyeaFhAY67AEZ78r%2BvsgzKEgEiWbF5OpoOXP6%2BGnD4E3Qt0myW71FxO4%2B%2B5F9mfJ8nTriUyeZkyZ7YBlUlTLweye4hLr68AS%2FsYmBoTIj2aJAzl0Z0PjFC7DuzBrj47f6nU7nftPgT%2Fft1Yi2Z6AIaBVLLJPBajs044lkygm%2B%2FNSH5LYq8bg%2BdCAYjEgNQm0vGX7pCRXZme93cmJ3GJ502%2Ff4mixSmVhd7VoYm93Nr%2B2sC%2BVGoLesXiOOVRl3QrYa%2BoAVS4YyoHGM4g9y6tJVaqt93c7HTjdEfQTo8jkoTgKlSwUHTwnNQHVkbrOYcCxvpUZlTQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210422T141452Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAUA2QCFAA3ONCLC6A%2F20210422%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=544dcd92daffb6b04cb927a13a463a7aabdf8c4268ef2cab8c2be99a9a330408'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "\n",
    "# This code outputs the URI path\n",
    "job['TranscriptionJob']['Transcript']['TranscriptFileUri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-convert",
   "metadata": {},
   "source": [
    "The URI path is long. Copy the entire link and use Linux's `!wget` to download the json to your local directory.\n",
    "\n",
    "Once it is there, you can rename it and view it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "verbal-sapphire",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name is too long, 1442 chars total.\n",
      "Trying to shorten...\n",
      "New name is asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAdRNaPfDMiuV3u31aSpBF7C%2FAHgH3s24wkgKSZNXdKqAiBjPmInCatJRyoHlbvGum626Y9N%2BW6tzNUNL%2FGL1ZWhpiq0AwgbEAIaDDI3NjY1NjQzMzE1MyIMgj.\n",
      "--2021-04-15 18:16:48--  https://s3.us-east-1.amazonaws.com/aws-transcribe-us-east-1-prod/795731225536/hindi-vine-wine/b4fd3625-d73a-4e9f-9500-d2934e3df281/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAdRNaPfDMiuV3u31aSpBF7C%2FAHgH3s24wkgKSZNXdKqAiBjPmInCatJRyoHlbvGum626Y9N%2BW6tzNUNL%2FGL1ZWhpiq0AwgbEAIaDDI3NjY1NjQzMzE1MyIMgj3l0XzpJmFXxvWnKpEDue80AyEvz8UWelPPLtgsDx3pmnPFJct8p3J%2BfazXqqV4j7Z1rtM8cHlVNPV2bMgRadgzMVZixA6XSSMBhLPn3pzP6KXv%2BU6VOdpQ91Ac%2BLvTZy79rbuWTkv8lPI4IRVdHHSqmaxvH%2FH1nURwJUYlsUWj2pfcNVqvydueZGIWsJ2Ok%2F3Lez5lKO92Q4kzDFP9A3YvB6pm%2FBeE3Y32KAXEH68OExmP00Zmq8CC8HLKatPK1EO3oxYnav77tfw9N7uIIcvauyDQoaWTB3EuGtp8gqW%2FjScnuGJRLrDDncZZ2FJ1JEGr%2FTPpQIkXYW2yv0QC%2Fll830iQooJUdXT%2FSXpdrvlAPtxEa2URVQMcbGyc%2FZZpJeT91yBNlq%2FxAvQ36LfzPbHgFcBuxhJERpMkUOpd3astbzd%2B%2FCh0ESFdoclvIFCwmOkm40GACKuCiv8WO%2BO%2FaeOeHEK2Rl%2BT3qWcZJs1eiYIEstYZltx08VgPZrUrkjC%2FIBDfPjiEVNdzbcdJsrXXEGDv1FLIS%2FMVen70y3WpV8w4P%2FhgwY67AGG5wJo%2B7RCpU6RGjnOk6ntyOL25QbckYWHivQdE1VPmFwfRGlI%2Fay5QhrA76oXNJmCXnLMDajzqlctf9feyyIJuDjO9WouHYNOCMWHLkLHJ9mevrorWiDlhthztobg5Zg0RypQZQYfMuNMx%2BtL5v6loVxB%2BckmLmWDdjmDGXkiu%2BhOt94xWKuhkiG7dohNGMKABbTkWBB9FWh3skTUGOh%2BmGxDfLWFkKyYRt34z24OciSfGExZbtzeSgtpraAColWAuvphoucVU93MfyEazEF9Qj8AXDh9M8q3bbDybD798TZlAb%2Fut0kK5ZOqzQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210415T181632Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAUA2QCFAAZSTT5J6P%2F20210415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=57fe290b0bba65d8c6f55c56347fc145d74c8e4e2b429d4823a8379412d60098\n",
      "Resolving s3.us-east-1.amazonaws.com (s3.us-east-1.amazonaws.com)... 52.216.233.109\n",
      "Connecting to s3.us-east-1.amazonaws.com (s3.us-east-1.amazonaws.com)|52.216.233.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1440 (1.4K) [application/octet-stream]\n",
      "Saving to: ‘asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAdRNaPfDMiuV3u31aSpBF7C%2FAHgH3s24wkgKSZNXdKqAiBjPmInCatJRyoHlbvGum626Y9N%2BW6tzNUNL%2FGL1ZWhpiq0AwgbEAIaDDI3NjY1NjQzMzE1MyIMgj’\n",
      "\n",
      "asrOutput.json?X-Am 100%[===================>]   1.41K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-04-15 18:16:48 (96.2 MB/s) - ‘asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAdRNaPfDMiuV3u31aSpBF7C%2FAHgH3s24wkgKSZNXdKqAiBjPmInCatJRyoHlbvGum626Y9N%2BW6tzNUNL%2FGL1ZWhpiq0AwgbEAIaDDI3NjY1NjQzMzE1MyIMgj’ saved [1440/1440]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code is used to download the transcription to our local folder\n",
    "!wget 'https://s3.us-east-1.amazonaws.com/aws-transcribe-us-east-1-prod/795731225536/hindi-vine-wine/b4fd3625-d73a-4e9f-9500-d2934e3df281/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjELL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAdRNaPfDMiuV3u31aSpBF7C%2FAHgH3s24wkgKSZNXdKqAiBjPmInCatJRyoHlbvGum626Y9N%2BW6tzNUNL%2FGL1ZWhpiq0AwgbEAIaDDI3NjY1NjQzMzE1MyIMgj3l0XzpJmFXxvWnKpEDue80AyEvz8UWelPPLtgsDx3pmnPFJct8p3J%2BfazXqqV4j7Z1rtM8cHlVNPV2bMgRadgzMVZixA6XSSMBhLPn3pzP6KXv%2BU6VOdpQ91Ac%2BLvTZy79rbuWTkv8lPI4IRVdHHSqmaxvH%2FH1nURwJUYlsUWj2pfcNVqvydueZGIWsJ2Ok%2F3Lez5lKO92Q4kzDFP9A3YvB6pm%2FBeE3Y32KAXEH68OExmP00Zmq8CC8HLKatPK1EO3oxYnav77tfw9N7uIIcvauyDQoaWTB3EuGtp8gqW%2FjScnuGJRLrDDncZZ2FJ1JEGr%2FTPpQIkXYW2yv0QC%2Fll830iQooJUdXT%2FSXpdrvlAPtxEa2URVQMcbGyc%2FZZpJeT91yBNlq%2FxAvQ36LfzPbHgFcBuxhJERpMkUOpd3astbzd%2B%2FCh0ESFdoclvIFCwmOkm40GACKuCiv8WO%2BO%2FaeOeHEK2Rl%2BT3qWcZJs1eiYIEstYZltx08VgPZrUrkjC%2FIBDfPjiEVNdzbcdJsrXXEGDv1FLIS%2FMVen70y3WpV8w4P%2FhgwY67AGG5wJo%2B7RCpU6RGjnOk6ntyOL25QbckYWHivQdE1VPmFwfRGlI%2Fay5QhrA76oXNJmCXnLMDajzqlctf9feyyIJuDjO9WouHYNOCMWHLkLHJ9mevrorWiDlhthztobg5Zg0RypQZQYfMuNMx%2BtL5v6loVxB%2BckmLmWDdjmDGXkiu%2BhOt94xWKuhkiG7dohNGMKABbTkWBB9FWh3skTUGOh%2BmGxDfLWFkKyYRt34z24OciSfGExZbtzeSgtpraAColWAuvphoucVU93MfyEazEF9Qj8AXDh9M8q3bbDybD798TZlAb%2Fut0kK5ZOqzQ%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210415T181632Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAUA2QCFAAZSTT5J6P%2F20210415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=57fe290b0bba65d8c6f55c56347fc145d74c8e4e2b429d4823a8379412d60098'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
